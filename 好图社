#http://www.haogirl.net/pic/  套图爬取
#2017.12.5星期二下午




#coding=utf-8
import requests
from bs4 import BeautifulSoup
headers = {'User-Agent':"Mozilla/5.0 (Windows NT 6.1; WOW64) 
AppleWebKit/537.1 (KHTML, like Gecko) 
Chrome/22.0.1207.1 Safari/537.1" }
onetar_url = 'http://www.haogirl.net/pic/9429'                       #单页图片链接           
onetar_html = requests.get(onetar_url,headers=headers)               # 解析html    
onetar_soup = BeautifulSoup(onetar_html.text,'lxml')
onetarimg_url = onetar_soup.find('div',class_='text')                 #查找  
onetarimg_urls=onetarimg_url.find_all('img')
i =1
for image in onetarimg_urls:
    image_url = image['src']
    r = "http://www.haogirl.net/"+image_url[3:]                      #由于img的链接是..//xxx所以截取第三个元素到后面
    re = requests.get(r)
    re.encoding='utf-8'
    with open ('%d.jpg'%i,'wb') as f:
        f.write(re.content)
        i+=1
******************************************************************************************************
#!/usr/bin/env python
# -*- coding: utf-8 -*-
import requests
from bs4 import BeautifulSoup


page=37524
while(1):#使用循环一直进行
	i=1
	url = 'http://www.jdlingyu.fun/'+str(page)+'/'
	print(url)
	headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'
	}
	html = requests.get(url,headers=headers)
	if html.status_code == requests.codes.ok:#判断状态码，排除404
		try:
			htmlsoup = BeautifulSoup(html.text,'lxml')
			title = htmlsoup.find('h2',class_='main-title').text  #get  a photo  title
			photourl = htmlsoup.find('div',class_='main-body').find_all('a')
		except AttributeError:
			page+=1	
			continue;#继续循环，因为有的url会跳转到home页，也就咩有find_all这些属性
		except requests.exceptions.ConnectionError:
			page+=1
			continue
		for j in photourl:
			href = j['href']
			re = requests.get(href)
			with open(title+'.%d.jpg'%i,'wb') as f:
				print("it is downloading "+title+" NO.%d"%i)
				f.write(re.content)
		    	i+=1
		page+=1
		i=1
	else:
		page+=1
